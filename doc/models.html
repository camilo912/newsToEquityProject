<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: module models</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head><body bgcolor="#f0f0f8">

<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="heading">
<tr bgcolor="#7799ee">
<td valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial">&nbsp;<br><big><big><strong>models</strong></big></big></font></td
><td align=right valign=bottom
><font color="#ffffff" face="helvetica, arial"><a href=".">index</a><br><a href="file:d%3A%5Conedrive%20-%20inversiones%20internacionales%20grupo%20sura%20s.a%5Cnewstoequity%5Cnewstoequityproject%5Cmodels.py">d:\onedrive - inversiones internacionales grupo sura s.a\newstoequity\newstoequityproject\models.py</a></font></td></tr></table>
    <p></p>
<p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#aa55cc">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Modules</strong></big></font></td></tr>
    
<tr><td bgcolor="#aa55cc"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><table width="100%" summary="list"><tr><td width="25%" valign=top><a href="torch.nn.functional.html">torch.nn.functional</a><br>
</td><td width="25%" valign=top><a href="torch.nn.html">torch.nn</a><br>
</td><td width="25%" valign=top><a href="torch.optim.html">torch.optim</a><br>
</td><td width="25%" valign=top><a href="torch.html">torch</a><br>
</td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ee77aa">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Classes</strong></big></font></td></tr>
    
<tr><td bgcolor="#ee77aa"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl>
<dt><font face="helvetica, arial"><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>(<a href="builtins.html#object">builtins.object</a>)
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="models.html#Model0">Model0</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model1">Model1</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model10">Model10</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model11">Model11</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model12">Model12</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model13">Model13</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model14">Model14</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model2">Model2</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model3">Model3</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model4">Model4</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model5">Model5</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model6">Model6</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model7">Model7</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model8">Model8</a>
</font></dt><dt><font face="helvetica, arial"><a href="models.html#Model9">Model9</a>
</font></dt></dl>
</dd>
</dl>
 <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model0">class <strong>Model0</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model0-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model0-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model0-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model0-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model0">Model0</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model0-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model0-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model0-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<dl><dt><a name="Model0-init_hidden"><strong>init_hidden</strong></a>(self, batch_size)</dt></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model0-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model0-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model0-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model0-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model0-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model0-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model0-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model0-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model0-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model0-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model0-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model0-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model0-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model0-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model0-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model0-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model0-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model0-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model0-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model0-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model0-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model0-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model0-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model0-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model0-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model0-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model0-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model0-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model0-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model0-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model0-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model0-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model0-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model0-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model0-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model0-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model0-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model0-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model0-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model0-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model0-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model0-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model0-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model0-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model0-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model0-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model0-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model0-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model0-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model0-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model0-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model0-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model1">class <strong>Model1</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model1-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model1-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model1-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model1-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model1">Model1</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model1-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model1-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model1-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<dl><dt><a name="Model1-init_hidden"><strong>init_hidden</strong></a>(self, batch_size)</dt></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model1-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model1-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model1-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model1-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model1-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model1-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model1-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model1-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model1-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model1-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model1-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model1-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model1-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model1-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model1-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model1-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model1-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model1-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model1-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model1-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model1-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model1-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model1-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model1-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model1-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model1-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model1-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model1-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model1-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model1-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model1-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model1-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model1-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model1-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model1-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model1-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model1-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model1-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model1-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model1-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model1-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model1-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model1-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model1-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model1-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model1-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model1-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model1-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model1-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model1-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model1-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model1-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model10">class <strong>Model10</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model10-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model10-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model10-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model10-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model10">Model10</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model10-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model10-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model10-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model10-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model10-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model10-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model10-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model10-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model10-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model10-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model10-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model10-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model10-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model10-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model10-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model10-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model10-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model10-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model10-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model10-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model10-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model10-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model10-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model10-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model10-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model10-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model10-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model10-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model10-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model10-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model10-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model10-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model10-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model10-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model10-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model10-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model10-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model10-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model10-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model10-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model10-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model10-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model10-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model10-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model10-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model10-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model10-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model10-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model10-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model10-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model10-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model10-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model10-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model10-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model10-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model11">class <strong>Model11</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model11-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model11-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model11-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model11-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model11">Model11</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model11-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model11-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model11-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model11-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model11-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model11-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model11-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model11-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model11-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model11-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model11-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model11-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model11-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model11-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model11-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model11-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model11-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model11-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model11-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model11-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model11-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model11-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model11-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model11-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model11-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model11-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model11-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model11-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model11-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model11-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model11-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model11-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model11-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model11-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model11-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model11-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model11-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model11-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model11-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model11-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model11-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model11-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model11-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model11-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model11-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model11-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model11-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model11-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model11-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model11-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model11-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model11-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model11-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model11-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model11-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model12">class <strong>Model12</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model12-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model12-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model12-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model12-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model12">Model12</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model12-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model12-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model12-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model12-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model12-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model12-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model12-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model12-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model12-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model12-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model12-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model12-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model12-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model12-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model12-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model12-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model12-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model12-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model12-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model12-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model12-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model12-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model12-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model12-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model12-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model12-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model12-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model12-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model12-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model12-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model12-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model12-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model12-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model12-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model12-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model12-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model12-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model12-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model12-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model12-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model12-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model12-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model12-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model12-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model12-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model12-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model12-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model12-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model12-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model12-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model12-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model12-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model12-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model12-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model12-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model13">class <strong>Model13</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model13-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model13-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model13-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model13-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model13">Model13</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model13-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model13-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model13-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model13-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model13-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model13-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model13-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model13-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model13-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model13-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model13-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model13-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model13-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model13-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model13-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model13-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model13-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model13-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model13-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model13-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model13-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model13-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model13-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model13-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model13-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model13-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model13-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model13-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model13-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model13-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model13-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model13-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model13-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model13-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model13-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model13-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model13-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model13-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model13-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model13-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model13-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model13-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model13-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model13-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model13-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model13-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model13-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model13-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model13-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model13-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model13-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model13-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model13-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model13-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model13-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model14">class <strong>Model14</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model14-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model14-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model14-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model14-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model14">Model14</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model14-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model14-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model14-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model14-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model14-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model14-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model14-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model14-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model14-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model14-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model14-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model14-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model14-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model14-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model14-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model14-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model14-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model14-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model14-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model14-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model14-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model14-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model14-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model14-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model14-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model14-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model14-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model14-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model14-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model14-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model14-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model14-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model14-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model14-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model14-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model14-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model14-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model14-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model14-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model14-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model14-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model14-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model14-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model14-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model14-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model14-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model14-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model14-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model14-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model14-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model14-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model14-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model14-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model14-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model14-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model2">class <strong>Model2</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model2-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model2-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model2-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model2-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model2">Model2</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model2-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model2-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model2-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<dl><dt><a name="Model2-init_hidden"><strong>init_hidden</strong></a>(self, batch_size)</dt></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model2-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model2-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model2-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model2-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model2-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model2-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model2-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model2-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model2-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model2-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model2-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model2-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model2-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model2-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model2-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model2-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model2-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model2-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model2-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model2-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model2-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model2-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model2-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model2-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model2-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model2-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model2-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model2-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model2-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model2-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model2-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model2-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model2-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model2-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model2-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model2-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model2-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model2-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model2-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model2-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model2-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model2-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model2-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model2-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model2-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model2-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model2-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model2-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model2-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model2-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model2-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model2-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model3">class <strong>Model3</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model3-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model3-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model3-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model3-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model3">Model3</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model3-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model3-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model3-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<dl><dt><a name="Model3-init_hidden"><strong>init_hidden</strong></a>(self, batch_size)</dt></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model3-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model3-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model3-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model3-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model3-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model3-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model3-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model3-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model3-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model3-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model3-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model3-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model3-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model3-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model3-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model3-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model3-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model3-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model3-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model3-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model3-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model3-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model3-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model3-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model3-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model3-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model3-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model3-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model3-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model3-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model3-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model3-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model3-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model3-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model3-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model3-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model3-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model3-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model3-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model3-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model3-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model3-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model3-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model3-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model3-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model3-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model3-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model3-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model3-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model3-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model3-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model3-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model4">class <strong>Model4</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model4-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model4-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model4-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model4-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model4">Model4</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model4-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model4-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model4-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<dl><dt><a name="Model4-init_hidden"><strong>init_hidden</strong></a>(self, batch_size)</dt></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model4-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model4-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model4-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model4-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model4-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model4-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model4-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model4-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model4-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model4-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model4-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model4-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model4-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model4-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model4-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model4-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model4-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model4-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model4-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model4-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model4-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model4-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model4-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model4-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model4-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model4-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model4-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model4-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model4-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model4-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model4-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model4-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model4-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model4-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model4-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model4-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model4-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model4-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model4-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model4-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model4-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model4-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model4-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model4-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model4-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model4-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model4-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model4-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model4-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model4-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model4-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model4-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model5">class <strong>Model5</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model5-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model5-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model5-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model5-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model5">Model5</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model5-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model5-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model5-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model5-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model5-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model5-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model5-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model5-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model5-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model5-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model5-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model5-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model5-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model5-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model5-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model5-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model5-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model5-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model5-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model5-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model5-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model5-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model5-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model5-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model5-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model5-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model5-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model5-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model5-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model5-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model5-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model5-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model5-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model5-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model5-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model5-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model5-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model5-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model5-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model5-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model5-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model5-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model5-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model5-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model5-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model5-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model5-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model5-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model5-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model5-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model5-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model5-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model5-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model5-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model5-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model6">class <strong>Model6</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model6-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model6-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model6-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model6-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model6">Model6</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model6-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model6-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model6-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model6-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model6-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model6-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model6-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model6-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model6-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model6-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model6-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model6-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model6-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model6-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model6-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model6-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model6-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model6-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model6-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model6-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model6-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model6-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model6-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model6-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model6-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model6-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model6-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model6-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model6-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model6-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model6-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model6-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model6-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model6-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model6-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model6-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model6-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model6-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model6-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model6-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model6-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model6-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model6-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model6-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model6-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model6-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model6-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model6-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model6-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model6-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model6-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model6-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model6-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model6-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model6-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model7">class <strong>Model7</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model7-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model7-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model7-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model7-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model7">Model7</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model7-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model7-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model7-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model7-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model7-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model7-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model7-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model7-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model7-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model7-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model7-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model7-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model7-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model7-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model7-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model7-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model7-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model7-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model7-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model7-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model7-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model7-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model7-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model7-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model7-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model7-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model7-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model7-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model7-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model7-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model7-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model7-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model7-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model7-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model7-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model7-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model7-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model7-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model7-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model7-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model7-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model7-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model7-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model7-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model7-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model7-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model7-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model7-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model7-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model7-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model7-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model7-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model7-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model7-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model7-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model8">class <strong>Model8</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model8-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model8-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model8-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model8-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model8">Model8</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model8-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model8-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model8-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model8-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model8-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model8-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model8-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model8-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model8-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model8-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model8-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model8-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model8-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model8-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model8-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model8-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model8-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model8-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model8-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model8-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model8-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model8-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model8-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model8-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model8-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model8-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model8-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model8-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model8-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model8-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model8-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model8-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model8-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model8-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model8-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model8-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model8-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model8-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model8-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model8-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model8-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model8-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model8-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model8-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model8-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model8-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model8-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model8-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model8-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model8-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model8-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model8-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model8-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model8-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model8-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table> <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="Model9">class <strong>Model9</strong></a>(<a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Base&nbsp;class&nbsp;for&nbsp;all&nbsp;neural&nbsp;network&nbsp;modules.<br>
&nbsp;<br>
Your&nbsp;models&nbsp;should&nbsp;also&nbsp;subclass&nbsp;this&nbsp;class.<br>
&nbsp;<br>
Modules&nbsp;can&nbsp;also&nbsp;contain&nbsp;other&nbsp;Modules,&nbsp;allowing&nbsp;to&nbsp;nest&nbsp;them&nbsp;in<br>
a&nbsp;tree&nbsp;structure.&nbsp;You&nbsp;can&nbsp;assign&nbsp;the&nbsp;submodules&nbsp;as&nbsp;regular&nbsp;attributes::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn&nbsp;as&nbsp;nn<br>
&nbsp;&nbsp;&nbsp;&nbsp;import&nbsp;torch.nn.functional&nbsp;as&nbsp;F<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;class&nbsp;Model(nn.<a href="torch.nn.modules.module.html#Module">Module</a>):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model9-__init__">__init__</a>(self):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super(Model,&nbsp;self).<a href="#Model9-__init__">__init__</a>()<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv1</strong>&nbsp;=&nbsp;nn.Conv2d(1,&nbsp;20,&nbsp;5)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self.<strong>conv2</strong>&nbsp;=&nbsp;nn.Conv2d(20,&nbsp;20,&nbsp;5)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<a href="#Model9-forward">forward</a>(self,&nbsp;x):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x&nbsp;=&nbsp;F.relu(self.conv1(x))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;F.relu(self.conv2(x))<br>
&nbsp;<br>
Submodules&nbsp;assigned&nbsp;in&nbsp;this&nbsp;way&nbsp;will&nbsp;be&nbsp;registered,&nbsp;and&nbsp;will&nbsp;have&nbsp;their<br>
parameters&nbsp;converted&nbsp;too&nbsp;when&nbsp;you&nbsp;call&nbsp;`.<a href="#Model9-cuda">cuda</a>()`,&nbsp;etc.<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="models.html#Model9">Model9</a></dd>
<dd><a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a></dd>
<dd><a href="builtins.html#object">builtins.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="Model9-__init__"><strong>__init__</strong></a>(self, embedding_dim, n_hidden, n_out, drop_p)</dt><dd><tt>Initialize&nbsp;self.&nbsp;&nbsp;See&nbsp;help(<a href="#Model9-type">type</a>(self))&nbsp;for&nbsp;accurate&nbsp;signature.</tt></dd></dl>

<dl><dt><a name="Model9-forward"><strong>forward</strong></a>(self, seq, lengths, train=False)</dt><dd><tt>Defines&nbsp;the&nbsp;computation&nbsp;performed&nbsp;at&nbsp;every&nbsp;call.<br>
&nbsp;<br>
Should&nbsp;be&nbsp;overridden&nbsp;by&nbsp;all&nbsp;subclasses.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;Although&nbsp;the&nbsp;recipe&nbsp;for&nbsp;forward&nbsp;pass&nbsp;needs&nbsp;to&nbsp;be&nbsp;defined&nbsp;within<br>
&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;function,&nbsp;one&nbsp;should&nbsp;call&nbsp;the&nbsp;:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;instance&nbsp;afterwards<br>
&nbsp;&nbsp;&nbsp;&nbsp;instead&nbsp;of&nbsp;this&nbsp;since&nbsp;the&nbsp;former&nbsp;takes&nbsp;care&nbsp;of&nbsp;running&nbsp;the<br>
&nbsp;&nbsp;&nbsp;&nbsp;registered&nbsp;hooks&nbsp;while&nbsp;the&nbsp;latter&nbsp;silently&nbsp;ignores&nbsp;them.</tt></dd></dl>

<hr>
Methods inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><a name="Model9-__call__"><strong>__call__</strong></a>(self, *input, **kwargs)</dt><dd><tt>Call&nbsp;self&nbsp;as&nbsp;a&nbsp;function.</tt></dd></dl>

<dl><dt><a name="Model9-__delattr__"><strong>__delattr__</strong></a>(self, name)</dt><dd><tt>Implement&nbsp;delattr(self,&nbsp;name).</tt></dd></dl>

<dl><dt><a name="Model9-__dir__"><strong>__dir__</strong></a>(self)</dt><dd><tt><a href="#Model9-__dir__">__dir__</a>()&nbsp;-&gt;&nbsp;list<br>
default&nbsp;dir()&nbsp;implementation</tt></dd></dl>

<dl><dt><a name="Model9-__getattr__"><strong>__getattr__</strong></a>(self, name)</dt></dl>

<dl><dt><a name="Model9-__repr__"><strong>__repr__</strong></a>(self)</dt><dd><tt>Return&nbsp;repr(self).</tt></dd></dl>

<dl><dt><a name="Model9-__setattr__"><strong>__setattr__</strong></a>(self, name, value)</dt><dd><tt>Implement&nbsp;setattr(self,&nbsp;name,&nbsp;value).</tt></dd></dl>

<dl><dt><a name="Model9-__setstate__"><strong>__setstate__</strong></a>(self, state)</dt></dl>

<dl><dt><a name="Model9-add_module"><strong>add_module</strong></a>(self, name, module)</dt><dd><tt>Adds&nbsp;a&nbsp;child&nbsp;module&nbsp;to&nbsp;the&nbsp;current&nbsp;module.<br>
&nbsp;<br>
The&nbsp;module&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;the&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;child&nbsp;module.&nbsp;The&nbsp;child&nbsp;module&nbsp;can&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accessed&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;child&nbsp;module&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model9-apply"><strong>apply</strong></a>(self, fn)</dt><dd><tt>Applies&nbsp;``fn``&nbsp;recursively&nbsp;to&nbsp;every&nbsp;submodule&nbsp;(as&nbsp;returned&nbsp;by&nbsp;``.<a href="#Model9-children">children</a>()``)<br>
as&nbsp;well&nbsp;as&nbsp;self.&nbsp;Typical&nbsp;use&nbsp;includes&nbsp;initializing&nbsp;the&nbsp;parameters&nbsp;of&nbsp;a&nbsp;model<br>
(see&nbsp;also&nbsp;:ref:`torch-nn-init`).<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;fn&nbsp;(:class:`<a href="torch.nn.modules.module.html#Module">Module</a>`&nbsp;-&gt;&nbsp;None):&nbsp;function&nbsp;to&nbsp;be&nbsp;applied&nbsp;to&nbsp;each&nbsp;submodule<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;def&nbsp;init_weights(m):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;<a href="#Model9-type">type</a>(m)&nbsp;==&nbsp;nn.Linear:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;m.weight.data.fill_(1.0)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(m.weight)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(nn.Linear(2,&nbsp;2),&nbsp;nn.Linear(2,&nbsp;2))<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net.<a href="#Model9-apply">apply</a>(init_weights)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;1.,&nbsp;&nbsp;1.],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[&nbsp;1.,&nbsp;&nbsp;1.]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Sequential(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)</tt></dd></dl>

<dl><dt><a name="Model9-children"><strong>children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;child&nbsp;module</tt></dd></dl>

<dl><dt><a name="Model9-cpu"><strong>cpu</strong></a>(self)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;CPU.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model9-cuda"><strong>cuda</strong></a>(self, device=None)</dt><dd><tt>Moves&nbsp;all&nbsp;model&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;the&nbsp;GPU.<br>
&nbsp;<br>
This&nbsp;also&nbsp;makes&nbsp;associated&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;different&nbsp;objects.&nbsp;So<br>
it&nbsp;should&nbsp;be&nbsp;called&nbsp;before&nbsp;constructing&nbsp;optimizer&nbsp;if&nbsp;the&nbsp;module&nbsp;will<br>
live&nbsp;on&nbsp;GPU&nbsp;while&nbsp;being&nbsp;optimized.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(int,&nbsp;optional):&nbsp;if&nbsp;specified,&nbsp;all&nbsp;parameters&nbsp;will&nbsp;be<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;copied&nbsp;to&nbsp;that&nbsp;device<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model9-double"><strong>double</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``double``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model9-eval"><strong>eval</strong></a>(self)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;evaluation&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.</tt></dd></dl>

<dl><dt><a name="Model9-extra_repr"><strong>extra_repr</strong></a>(self)</dt><dd><tt>Set&nbsp;the&nbsp;extra&nbsp;representation&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
To&nbsp;print&nbsp;customized&nbsp;extra&nbsp;information,&nbsp;you&nbsp;should&nbsp;reimplement<br>
this&nbsp;method&nbsp;in&nbsp;your&nbsp;own&nbsp;modules.&nbsp;Both&nbsp;single-line&nbsp;and&nbsp;multi-line<br>
strings&nbsp;are&nbsp;acceptable.</tt></dd></dl>

<dl><dt><a name="Model9-float"><strong>float</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;float&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model9-half"><strong>half</strong></a>(self)</dt><dd><tt>Casts&nbsp;all&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;``half``&nbsp;datatype.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model9-load_state_dict"><strong>load_state_dict</strong></a>(self, state_dict, strict=True)</dt><dd><tt>Copies&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;from&nbsp;:attr:`state_dict`&nbsp;into<br>
this&nbsp;module&nbsp;and&nbsp;its&nbsp;descendants.&nbsp;If&nbsp;:attr:`strict`&nbsp;is&nbsp;``True``,&nbsp;then<br>
the&nbsp;keys&nbsp;of&nbsp;:attr:`state_dict`&nbsp;must&nbsp;exactly&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned<br>
by&nbsp;this&nbsp;module's&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;state_dict&nbsp;(dict):&nbsp;a&nbsp;dict&nbsp;containing&nbsp;parameters&nbsp;and<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;persistent&nbsp;buffers.<br>
&nbsp;&nbsp;&nbsp;&nbsp;strict&nbsp;(bool,&nbsp;optional):&nbsp;whether&nbsp;to&nbsp;strictly&nbsp;enforce&nbsp;that&nbsp;the&nbsp;keys<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in&nbsp;:attr:`state_dict`&nbsp;match&nbsp;the&nbsp;keys&nbsp;returned&nbsp;by&nbsp;this&nbsp;module's<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:meth:`~torch.nn.<a href="torch.nn.modules.module.html#Module">Module</a>.state_dict`&nbsp;function.&nbsp;Default:&nbsp;``True``</tt></dd></dl>

<dl><dt><a name="Model9-modules"><strong>modules</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;a&nbsp;module&nbsp;in&nbsp;the&nbsp;network<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model9-modules">modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;)<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)</tt></dd></dl>

<dl><dt><a name="Model9-named_children"><strong>named_children</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;immediate&nbsp;children&nbsp;modules,&nbsp;yielding&nbsp;both<br>
the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;containing&nbsp;a&nbsp;name&nbsp;and&nbsp;child&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;module&nbsp;in&nbsp;model.<a href="#Model9-named_children">named_children</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['conv4',&nbsp;'conv5']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(module)</tt></dd></dl>

<dl><dt><a name="Model9-named_modules"><strong>named_modules</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;all&nbsp;modules&nbsp;in&nbsp;the&nbsp;network,&nbsp;yielding<br>
both&nbsp;the&nbsp;name&nbsp;of&nbsp;the&nbsp;module&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;module&nbsp;itself.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>):&nbsp;Tuple&nbsp;of&nbsp;name&nbsp;and&nbsp;module<br>
&nbsp;<br>
Note:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Duplicate&nbsp;modules&nbsp;are&nbsp;returned&nbsp;only&nbsp;once.&nbsp;In&nbsp;the&nbsp;following<br>
&nbsp;&nbsp;&nbsp;&nbsp;example,&nbsp;``l``&nbsp;will&nbsp;be&nbsp;returned&nbsp;only&nbsp;once.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;l&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;net&nbsp;=&nbsp;nn.Sequential(l,&nbsp;l)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;idx,&nbsp;m&nbsp;in&nbsp;enumerate(net.<a href="#Model9-named_modules">named_modules</a>()):<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(idx,&nbsp;'-&gt;',&nbsp;m)<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;-&gt;&nbsp;('',&nbsp;Sequential&nbsp;(<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(0):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1):&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;))<br>
&nbsp;&nbsp;&nbsp;&nbsp;1&nbsp;-&gt;&nbsp;('0',&nbsp;Linear&nbsp;(2&nbsp;-&gt;&nbsp;2))</tt></dd></dl>

<dl><dt><a name="Model9-named_parameters"><strong>named_parameters</strong></a>(self, memo=None, prefix='')</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters,&nbsp;yielding&nbsp;both&nbsp;the<br>
name&nbsp;of&nbsp;the&nbsp;parameter&nbsp;as&nbsp;well&nbsp;as&nbsp;the&nbsp;parameter&nbsp;itself<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;(string,&nbsp;Parameter):&nbsp;Tuple&nbsp;containing&nbsp;the&nbsp;name&nbsp;and&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;name,&nbsp;param&nbsp;in&nbsp;self.<a href="#Model9-named_parameters">named_parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;name&nbsp;in&nbsp;['bias']:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(param.size())</tt></dd></dl>

<dl><dt><a name="Model9-parameters"><strong>parameters</strong></a>(self)</dt><dd><tt>Returns&nbsp;an&nbsp;iterator&nbsp;over&nbsp;module&nbsp;parameters.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;passed&nbsp;to&nbsp;an&nbsp;optimizer.<br>
&nbsp;<br>
Yields:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter:&nbsp;module&nbsp;parameter<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;for&nbsp;param&nbsp;in&nbsp;model.<a href="#Model9-parameters">parameters</a>():<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(<a href="#Model9-type">type</a>(param.data),&nbsp;param.size())<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&lt;class&nbsp;'torch.FloatTensor'&gt;&nbsp;(20L,&nbsp;1L,&nbsp;5L,&nbsp;5L)</tt></dd></dl>

<dl><dt><a name="Model9-register_backward_hook"><strong>register_backward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;backward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;the&nbsp;gradients&nbsp;with&nbsp;respect&nbsp;to&nbsp;module<br>
inputs&nbsp;are&nbsp;computed.&nbsp;The&nbsp;hook&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;grad_input,&nbsp;grad_output)&nbsp;-&gt;&nbsp;Tensor&nbsp;or&nbsp;None<br>
&nbsp;<br>
The&nbsp;:attr:`grad_input`&nbsp;and&nbsp;:attr:`grad_output`&nbsp;may&nbsp;be&nbsp;tuples&nbsp;if&nbsp;the<br>
module&nbsp;has&nbsp;multiple&nbsp;inputs&nbsp;or&nbsp;outputs.&nbsp;The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;its<br>
arguments,&nbsp;but&nbsp;it&nbsp;can&nbsp;optionally&nbsp;return&nbsp;a&nbsp;new&nbsp;gradient&nbsp;with&nbsp;respect&nbsp;to<br>
input&nbsp;that&nbsp;will&nbsp;be&nbsp;used&nbsp;in&nbsp;place&nbsp;of&nbsp;:attr:`grad_input`&nbsp;in&nbsp;subsequent<br>
computations.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model9-register_buffer"><strong>register_buffer</strong></a>(self, name, tensor)</dt><dd><tt>Adds&nbsp;a&nbsp;persistent&nbsp;buffer&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
This&nbsp;is&nbsp;typically&nbsp;used&nbsp;to&nbsp;register&nbsp;a&nbsp;buffer&nbsp;that&nbsp;should&nbsp;not&nbsp;to&nbsp;be<br>
considered&nbsp;a&nbsp;model&nbsp;parameter.&nbsp;For&nbsp;example,&nbsp;BatchNorm's&nbsp;``running_mean``<br>
is&nbsp;not&nbsp;a&nbsp;parameter,&nbsp;but&nbsp;is&nbsp;part&nbsp;of&nbsp;the&nbsp;persistent&nbsp;state.<br>
&nbsp;<br>
Buffers&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;attributes&nbsp;using&nbsp;given&nbsp;names.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;buffer.&nbsp;The&nbsp;buffer&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(Tensor):&nbsp;buffer&nbsp;to&nbsp;be&nbsp;registered.<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;self.<a href="#Model9-register_buffer">register_buffer</a>('running_mean',&nbsp;torch.zeros(num_features))</tt></dd></dl>

<dl><dt><a name="Model9-register_forward_hook"><strong>register_forward_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;after&nbsp;:func:`forward`&nbsp;has&nbsp;computed&nbsp;an&nbsp;output.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input,&nbsp;output)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input&nbsp;or&nbsp;output.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model9-register_forward_pre_hook"><strong>register_forward_pre_hook</strong></a>(self, hook)</dt><dd><tt>Registers&nbsp;a&nbsp;forward&nbsp;pre-hook&nbsp;on&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;hook&nbsp;will&nbsp;be&nbsp;called&nbsp;every&nbsp;time&nbsp;before&nbsp;:func:`forward`&nbsp;is&nbsp;invoked.<br>
It&nbsp;should&nbsp;have&nbsp;the&nbsp;following&nbsp;signature::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;hook(module,&nbsp;input)&nbsp;-&gt;&nbsp;None<br>
&nbsp;<br>
The&nbsp;hook&nbsp;should&nbsp;not&nbsp;modify&nbsp;the&nbsp;input.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;:class:`torch.utils.hooks.RemovableHandle`:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;handle&nbsp;that&nbsp;can&nbsp;be&nbsp;used&nbsp;to&nbsp;remove&nbsp;the&nbsp;added&nbsp;hook&nbsp;by&nbsp;calling<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;``handle.remove()``</tt></dd></dl>

<dl><dt><a name="Model9-register_parameter"><strong>register_parameter</strong></a>(self, name, param)</dt><dd><tt>Adds&nbsp;a&nbsp;parameter&nbsp;to&nbsp;the&nbsp;module.<br>
&nbsp;<br>
The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed&nbsp;as&nbsp;an&nbsp;attribute&nbsp;using&nbsp;given&nbsp;name.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;name&nbsp;(string):&nbsp;name&nbsp;of&nbsp;the&nbsp;parameter.&nbsp;The&nbsp;parameter&nbsp;can&nbsp;be&nbsp;accessed<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from&nbsp;this&nbsp;module&nbsp;using&nbsp;the&nbsp;given&nbsp;name<br>
&nbsp;&nbsp;&nbsp;&nbsp;parameter&nbsp;(Parameter):&nbsp;parameter&nbsp;to&nbsp;be&nbsp;added&nbsp;to&nbsp;the&nbsp;module.</tt></dd></dl>

<dl><dt><a name="Model9-share_memory"><strong>share_memory</strong></a>(self)</dt></dl>

<dl><dt><a name="Model9-state_dict"><strong>state_dict</strong></a>(self, destination=None, prefix='', keep_vars=False)</dt><dd><tt>Returns&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module.<br>
&nbsp;<br>
Both&nbsp;parameters&nbsp;and&nbsp;persistent&nbsp;buffers&nbsp;(e.g.&nbsp;running&nbsp;averages)&nbsp;are<br>
included.&nbsp;Keys&nbsp;are&nbsp;corresponding&nbsp;parameter&nbsp;and&nbsp;buffer&nbsp;names.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dict:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;dictionary&nbsp;containing&nbsp;a&nbsp;whole&nbsp;state&nbsp;of&nbsp;the&nbsp;module<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;module.<a href="#Model9-state_dict">state_dict</a>().keys()<br>
&nbsp;&nbsp;&nbsp;&nbsp;['bias',&nbsp;'weight']</tt></dd></dl>

<dl><dt><a name="Model9-to"><strong>to</strong></a>(self, *args, **kwargs)</dt><dd><tt>Moves&nbsp;and/or&nbsp;casts&nbsp;the&nbsp;parameters&nbsp;and&nbsp;buffers.<br>
&nbsp;<br>
This&nbsp;can&nbsp;be&nbsp;called&nbsp;as<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model9-to">to</a>(device=None,&nbsp;dtype=None,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model9-to">to</a>(dtype,&nbsp;non_blocking=False)<br>
&nbsp;<br>
..&nbsp;function::&nbsp;<a href="#Model9-to">to</a>(tensor,&nbsp;non_blocking=False)<br>
&nbsp;<br>
Its&nbsp;signature&nbsp;is&nbsp;similar&nbsp;to&nbsp;:meth:`torch.Tensor.to`,&nbsp;but&nbsp;only&nbsp;accepts<br>
floating&nbsp;point&nbsp;desired&nbsp;:attr:`dtype`&nbsp;s.&nbsp;In&nbsp;addition,&nbsp;this&nbsp;method&nbsp;will<br>
only&nbsp;cast&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dtype`<br>
(if&nbsp;given).&nbsp;The&nbsp;integral&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;will&nbsp;be&nbsp;moved<br>
:attr:`device`,&nbsp;if&nbsp;that&nbsp;is&nbsp;given,&nbsp;but&nbsp;with&nbsp;dtypes&nbsp;unchanged.&nbsp;When<br>
:attr:`non_blocking`&nbsp;is&nbsp;set,&nbsp;it&nbsp;tries&nbsp;to&nbsp;convert/move&nbsp;asynchronously<br>
with&nbsp;respect&nbsp;to&nbsp;the&nbsp;host&nbsp;if&nbsp;possible,&nbsp;e.g.,&nbsp;moving&nbsp;CPU&nbsp;Tensors&nbsp;with<br>
pinned&nbsp;memory&nbsp;to&nbsp;CUDA&nbsp;devices.<br>
&nbsp;<br>
See&nbsp;below&nbsp;for&nbsp;examples.<br>
&nbsp;<br>
..&nbsp;note::<br>
&nbsp;&nbsp;&nbsp;&nbsp;This&nbsp;method&nbsp;modifies&nbsp;the&nbsp;module&nbsp;in-place.<br>
&nbsp;<br>
Args:<br>
&nbsp;&nbsp;&nbsp;&nbsp;device&nbsp;(:class:`torch.device`):&nbsp;the&nbsp;desired&nbsp;device&nbsp;of&nbsp;the&nbsp;parameters<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;(:class:`torch.dtype`):&nbsp;the&nbsp;desired&nbsp;floating&nbsp;point&nbsp;type&nbsp;of<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the&nbsp;floating&nbsp;point&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor&nbsp;(torch.Tensor):&nbsp;Tensor&nbsp;whose&nbsp;dtype&nbsp;and&nbsp;device&nbsp;are&nbsp;the&nbsp;desired<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dtype&nbsp;and&nbsp;device&nbsp;for&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;in&nbsp;this&nbsp;module<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self<br>
&nbsp;<br>
Example::<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear&nbsp;=&nbsp;nn.Linear(2,&nbsp;2)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]])<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model9-to">to</a>(torch.double)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1913,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5113,&nbsp;-0.2325]],&nbsp;dtype=torch.float64)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;gpu1&nbsp;=&nbsp;torch.device("cuda:1")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model9-to">to</a>(gpu1,&nbsp;dtype=torch.half,&nbsp;non_blocking=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16,&nbsp;device='cuda:1')<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;cpu&nbsp;=&nbsp;torch.device("cpu")<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.<a href="#Model9-to">to</a>(cpu)<br>
&nbsp;&nbsp;&nbsp;&nbsp;Linear(in_features=2,&nbsp;out_features=2,&nbsp;bias=True)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&gt;&gt;&gt;&nbsp;linear.weight<br>
&nbsp;&nbsp;&nbsp;&nbsp;Parameter&nbsp;containing:<br>
&nbsp;&nbsp;&nbsp;&nbsp;tensor([[&nbsp;0.1914,&nbsp;-0.3420],<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[-0.5112,&nbsp;-0.2324]],&nbsp;dtype=torch.float16)</tt></dd></dl>

<dl><dt><a name="Model9-train"><strong>train</strong></a>(self, mode=True)</dt><dd><tt>Sets&nbsp;the&nbsp;module&nbsp;in&nbsp;training&nbsp;mode.<br>
&nbsp;<br>
This&nbsp;has&nbsp;any&nbsp;effect&nbsp;only&nbsp;on&nbsp;certain&nbsp;modules.&nbsp;See&nbsp;documentations&nbsp;of<br>
particular&nbsp;modules&nbsp;for&nbsp;details&nbsp;of&nbsp;their&nbsp;behaviors&nbsp;in&nbsp;training/evaluation<br>
mode,&nbsp;if&nbsp;they&nbsp;are&nbsp;affected,&nbsp;e.g.&nbsp;:class:`Dropout`,&nbsp;:class:`BatchNorm`,<br>
etc.<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model9-type"><strong>type</strong></a>(self, dst_type)</dt><dd><tt>Casts&nbsp;all&nbsp;parameters&nbsp;and&nbsp;buffers&nbsp;to&nbsp;:attr:`dst_type`.<br>
&nbsp;<br>
Arguments:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dst_type&nbsp;(type&nbsp;or&nbsp;string):&nbsp;the&nbsp;desired&nbsp;type<br>
&nbsp;<br>
Returns:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<a href="torch.nn.modules.module.html#Module">Module</a>:&nbsp;self</tt></dd></dl>

<dl><dt><a name="Model9-zero_grad"><strong>zero_grad</strong></a>(self)</dt><dd><tt>Sets&nbsp;gradients&nbsp;of&nbsp;all&nbsp;model&nbsp;parameters&nbsp;to&nbsp;zero.</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<hr>
Data and other attributes inherited from <a href="torch.nn.modules.module.html#Module">torch.nn.modules.module.Module</a>:<br>
<dl><dt><strong>dump_patches</strong> = False</dl>

</td></tr></table></td></tr></table>
</body></html>